'use client';
import { useEffect, useState, useRef, useMemo, useCallback, useTransition } from "react";
import { RealtimeAgent, RealtimeSession } from "@openai/agents/realtime";
import { generateUploadUrl } from "@/app/api/s3/s3";
import { v4 as uuidv4 } from "uuid";
import SmallHeader from "@/component/SmallHeader";
import BottomFixButton from "@/component/BottomFixButton";
import PlayIcon from "@/assets/icon/PlayIcon.svg";
import PauseIcon from "@/assets/icon/PauseIcon.svg";
import Spinner from "@/component/Spinner";
import { usePathname, useRouter } from "next/navigation";
import { standardizeToMP3 } from "@/app/utils/audioPreprocessing";
import buildPatientInstructions from "./buildPrompt";
import { loadVirtualPatient, VirtualPatient } from "@/utils/loadVirtualPatient";
type Props = { category: string; caseName: string };

const INITIAL_SECONDS = 12 * 60; // 720s = 12ë¶„
/* Â°C í¬ë§· */
const formatTemp = (t: number) => `${t.toFixed(1)}Â°C`;

export default function LiveCPXClient({ category, caseName }: Props) {
    const router = useRouter();

    // ===== ìƒíƒœê°’ =====
    const [isRecording, setIsRecording] = useState(false);
    const [volume, setVolume] = useState(0);
    const [connected, setConnected] = useState(false);
    const [isUploading, setIsUploading] = useState(false);
    const [seconds, setSeconds] = useState<number>(INITIAL_SECONDS);
    const [isFinished, setIsFinished] = useState(false);
    //í™˜ì caseData
    const [caseData, setCaseData] = useState<VirtualPatient | null>(null);
    const pathname = usePathname(); // í˜„ì¬ URL ê²½ë¡œ ì¶”ì 

    const [isPending, startTransition] = useTransition()
    //ì¼ì‹œì •ì§€ ì•ˆëœë‹¤ëŠ” ìƒíƒœë©”ì‹œì§€
    const [statusMessage, setStatusMessage] = useState<string | undefined>(undefined)

    /**stopSession */
    const stopAndResetSession = useCallback(async () => {
        try {
            // ì„¸ì…˜ ì¢…ë£Œ
            if (sessionRef.current) {
                await (sessionRef.current as any).close?.();
                sessionRef.current = null;
            }
            // ë…¹ìŒ ì¤‘ë‹¨
            if (recorderRef.current?.state === "recording") {
                recorderRef.current.stop();
            }
            recorderRef.current = null;
            userAudioChunks.current = [];
            cancelAnimationFrame(rafRef.current!);

            // ìƒíƒœ ì´ˆê¸°í™”
            setIsRecording(false);
            setConnected(false);
            setIsUploading(false);
            setIsFinished(false);
            setVolume(0);
            setSeconds(INITIAL_SECONDS);

        } catch (err) {
            console.warn(" ì„¸ì…˜ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜:", err);
        }
    }, []);

    /** ë¼ìš°íŠ¸ ë³€ê²½ ì‹œ ìë™ ì •ë¦¬ */
    useEffect(() => {
        // ê²½ë¡œê°€ /live-select/cpx ê°€ ì•„ë‹ˆë©´ ì •ë¦¬
        if (pathname !== "/live-select/cpx") {
            stopAndResetSession();
        }
    }, [pathname, stopAndResetSession]);

    /** í˜ì´ì§€ ì´íƒˆ(ìƒˆë¡œê³ ì¹¨, ë‹«ê¸°) ê°ì§€ */
    useEffect(() => {
        const handleUnload = () => {
            if (pathname === "/live-select/cpx") {
                stopAndResetSession();
            }
        };
        window.addEventListener("beforeunload", handleUnload);
        return () => {
            window.removeEventListener("beforeunload", handleUnload);
        };
    }, [pathname, stopAndResetSession]);

    /** ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬ (ex. Next.js ë¼ìš°íŒ… ì´ë™) */
    useEffect(() => {
        return () => {
            stopAndResetSession();
        };
    }, [stopAndResetSession]);
    useEffect(() => {
        let isMounted = true;

        async function fetchCaseData() {
            try {
                const data = await loadVirtualPatient(caseName);
                if (isMounted) setCaseData(data);
            } catch (err) {
                console.error("ê°€ìƒí™˜ì ë¡œë“œ ì‹¤íŒ¨:", err);
            }
        }

        if (caseName) fetchCaseData();

        return () => {
            isMounted = false;
        };
    }, [caseName]);

    // ===== ë ˆí¼ëŸ°ìŠ¤ =====
    const sessionRef = useRef<any>(null);
    const recorderRef = useRef<MediaRecorder | null>(null);
    const userAudioChunks = useRef<Blob[]>([]);
    const rafRef = useRef<number | null>(null);

    /** ğŸ§ ë³¼ë¥¨ ì—…ë°ì´íŠ¸ */
    const updateVolume = (analyser: AnalyserNode) => {
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        const loop = () => {
            analyser.getByteFrequencyData(dataArray);
            const avg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
            setVolume(avg / 255);
            rafRef.current = requestAnimationFrame(loop);
        };
        loop();
    };

    // ì¹´í…Œê³ ë¦¬/ì¼€ì´ìŠ¤ ë³€ê²½ ì‹œ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
    useEffect(() => {
        setIsRecording(false);
        setIsFinished(false);
        setSeconds(INITIAL_SECONDS);
    }, [category, caseName]);

    // íƒ€ì´ë¨¸ ì§„í–‰
    useEffect(() => {
        if (!isRecording || isFinished) return;
        const id = setInterval(() => {
            setSeconds((prev) => {
                if (prev <= 1) {
                    clearInterval(id);
                    setIsRecording(false);
                    setIsFinished(true);
                    return 0;
                }
                return prev - 1;
            });
        }, 1000);
        return () => clearInterval(id);
    }, [isRecording, isFinished]);

    /** ğŸ¤ ì„¸ì…˜ ì‹œì‘ */
    async function startSession() {
        try {
            const res = await fetch("/api/realtime-key");
            const { value } = await res.json();

            const agent = new RealtimeAgent({
                name: "í‘œì¤€í™” í™˜ì AI",
                instructions: buildPatientInstructions(caseData as VirtualPatient),
                voice: "ash"
            });

            const session: any = new RealtimeSession(agent, {
                model: "gpt-realtime-mini-2025-10-06",
            });
            sessionRef.current = session;

            await session.connect({
                apiKey: value,
                speed: 1.5,
                turnDetection: {
                    type: "server_vad", //ì„œë²„ ê¸°ë°˜ voice detection
                    silence_duration_ms: 200,   // 0.2ì´ˆ ì¹¨ë¬µ â†’ í„´ ì¢…ë£Œ íŒë‹¨
                    autoStart: false, //ë¨¼ì € ë°œí™”í•˜ì§€ ì•Šë„ë¡ ì„¤ì •
                    prefix_padding_ms: 150, //AI ë°œí™”ì‹œ ì•ë¶€ë¶„ ì˜ë¦¬ì§€ ì•Šê²Œ padding
                    min_duration_ms: 250, // ë„ˆë¬´ ì§§ì€ ìŒì„±(ìˆ¨ì†Œë¦¬ ë“±) ë¬´ì‹œ
                },
            });
            setConnected(true);

            // ğŸ™ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioCtx = new AudioContext();
            const micSrc = audioCtx.createMediaStreamSource(stream);
            const analyser = audioCtx.createAnalyser();
            micSrc.connect(analyser);
            updateVolume(analyser);

            // ğŸ™ ì‚¬ìš©ì ë…¹ìŒ
            const recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
            recorderRef.current = recorder;
            recorder.ondataavailable = async (e) => {
                if (e.data.size > 0) {
                    userAudioChunks.current.push(e.data);

                    // GPTë¡œ ì‹¤ì‹œê°„ ì „ì†¡
                    const buf = await e.data.arrayBuffer();
                    if ((sessionRef.current as any).input_audio_buffer) {
                        (sessionRef.current as any).input_audio_buffer.append(buf);
                    }
                }
            };

            recorder.start(500); // 500msë§ˆë‹¤ chunk ìƒì„±
            setIsRecording(true);
        } catch (err) {
            console.error("âŒ ì„¸ì…˜ ì—°ê²° ì‹¤íŒ¨:", err);
            alert("ì„¸ì…˜ ì—°ê²° ì‹¤íŒ¨ ë˜ëŠ” ë§ˆì´í¬ ì ‘ê·¼ ê±°ë¶€");
        }
    }

    /** â¹ ì„¸ì…˜ ì¢…ë£Œ + ì‚¬ìš©ì ìŒì„±ë§Œ ì—…ë¡œë“œ */
    async function stopSession() {
        try {
            setIsUploading(true);

            // MediaRecorder ì •ì§€
            if (recorderRef.current?.state === "recording") recorderRef.current.stop();

            // ì„¸ì…˜ ì¢…ë£Œ
            if (sessionRef.current) await (sessionRef.current as any).close?.();

            // ì‚¬ìš©ì ìŒì„± webm -> mp3 ë³€í™˜
            const userBlob = new Blob(userAudioChunks.current, { type: "audio/webm" });
            const userMP3 = await standardizeToMP3(userBlob);

            // S3 ì—…ë¡œë“œ
            const bucket = process.env.NEXT_PUBLIC_S3_BUCKET_NAME!;
            const userKey = `audio/user-audio-${uuidv4()}.mp3`;
            const uploadUrl = await generateUploadUrl(bucket, userKey);

            const res = await fetch(uploadUrl, {
                method: "PUT",
                headers: { "Content-Type": "audio/mpeg" },
                body: userMP3,
            });
            if (!res.ok) throw new Error("S3 ì—…ë¡œë“œ ì‹¤íŒ¨");

            // ì±„ì  í˜ì´ì§€ë¡œ ì´ë™
            startTransition(() => {
                router.push(`/score?s3Key=${encodeURIComponent(userKey)}&caseName=${encodeURIComponent(caseName)}`);
            })
        } catch (err) {
            console.error("âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜:", err);
            alert("ì—…ë¡œë“œ ì‹¤íŒ¨");
        } finally {
            cancelAnimationFrame(rafRef.current!);
            setIsRecording(false);
            setConnected(false);
            setIsUploading(false);
        }
    }

    const toggleRecording = () => {
        if (isRecording) {
            setStatusMessage('ê°€ìƒí™˜ìì™€ì˜ ëŒ€í™”ëŠ” ì¼ì‹œì •ì§€í•  ìˆ˜ ì—†ì–´ìš”')
            return;
        }
        if (!connected) startSession();
        else stopSession();
    };

    const vitalData = caseData?.properties.meta.vitals;

    const showTime = useCallback((sec: number) => {
        const mm = Math.floor(sec / 60).toString().padStart(2, "0");
        const ss = (sec % 60).toString().padStart(2, "0");
        return `${mm}:${ss}`;
    }, []);

    // 3ì´ˆ í›„ ìë™ ì‚¬ë¼ì§€ëŠ” toast
    useEffect(() => {
        if (statusMessage) {
            const timer = setTimeout(() => setStatusMessage(undefined), 3000);
            return () => clearTimeout(timer);
        }
    }, [statusMessage]);


    return (
        <div className="flex flex-col min-h-screen">
            <div className="flex flex-col">
                <SmallHeader
                    title={`${category} | ${caseName}`}
                    onClick={() => router.push("/live-select")}
                />

                {/* ì„¤ëª… */}
                <div className="px-8 pt-4">
                    <p className="text-[#210535] text-[18px] leading-relaxed">
                        {caseData?.description}
                    </p>
                </div>

                {/* ë°”ì´íƒˆí‘œ (2ì—´ ê·¸ë¦¬ë“œ) */}
                <div className="grid grid-cols-2 gap-y-4 gap-x-4 px-8 pt-4 pb-6">
                    <div className="flex gap-2">
                        <div className="text-[#210535] font-semibold text-[18px]">í˜ˆì••</div>
                        <div className="text-[#210535] text-[18px]">
                            {vitalData?.bp}
                        </div>
                    </div>

                    <div className="flex gap-2">
                        <div className="text-[#210535] font-semibold text-[18px]">ë§¥ë°•</div>
                        <div className="text-[#210535] text-[18px]">
                            {vitalData?.hr}
                        </div>
                    </div>

                    <div className="flex gap-2">
                        <div className="text-[#210535] font-semibold text-[18px]">í˜¸í¡ìˆ˜</div>
                        <div className="text-[#210535] text-[18px]">
                            {vitalData?.rr}
                        </div>
                    </div>

                    <div className="flex gap-2">
                        <div className="text-[#210535] font-semibold text-[18px]">ì²´ì˜¨</div>
                        <div className="text-[#210535] text-[18px]">
                            {formatTemp(Number(vitalData?.bt))}
                        </div>
                    </div>
                </div>

                <div className="px-8 flex-1 pb-[136px] flex flex-col items-center justify-center gap-[12px] relative overflow-hidden">
                    {/* ì¤‘ì•™ ë…¹ìŒ ë²„íŠ¼ + ë³¼ë¥¨ ì• ë‹ˆë©”ì´ì…˜ */}
                    <div className="relative">
                        {isRecording && (
                            <div
                                className="absolute rounded-full transition-transform duration-100 ease-out"
                                style={{
                                    width: "206px",
                                    height: "206px",
                                    top: "49%",
                                    left: "50%",
                                    transform: `translate(-50%, -50%) scale(${1 + volume * 1.5})`,
                                    opacity: 0.3,
                                    background:
                                        "radial-gradient(circle at center, #B1A5E8 0%, #B1A5E8 40%, #BBA6FF 80%, transparent 100%)",
                                    boxShadow: `0 0 ${40 + volume * 50}px #B1A5E8`,
                                }}
                            ></div>
                        )}

                        <button
                            type="button"
                            onClick={toggleRecording}
                            className="outline-none relative cursor-pointer hover:opacity-70
                                                    transition-transform duration-150 ease-out active:scale-90"
                            disabled={isUploading}
                        >
                            {isRecording ? (
                                <PauseIcon className="w-[240px] h-[240px] text-[#7553FC] opacity-70" />
                            ) : (
                                <PlayIcon className="w-[240px] h-[240px] text-[#7553FC]" />
                            )}
                        </button>

                    </div>
                    {/* íƒ€ì´ë¨¸ */}
                    <div className="font-semibold text-[36px] text-[#7553FC] flex gap-2 items-center">
                        {showTime(seconds)}
                    </div>
                </div>

                <BottomFixButton
                    disabled={isUploading || seconds == 720}
                    buttonName={"ì¢…ë£Œ ë° ì±„ì í•˜ê¸°"}
                    onClick={stopSession}
                    loading={isPending || isUploading}
                />
                {statusMessage && (
                    <div
                        className="
                        fixed bottom-30 left-1/2 -translate-x-1/2 
                        bg-[#c7beeeff] text-[#210535] text-[18px] font-medium 
                        px-4 py-3 rounded-xl shadow-lg flex z-[100]
                        animate-slideUpFade flex justify-center items-center w-[calc(100%-40px)]
                        "
                    >
                        {statusMessage}
                    </div>
                )}
            </div>
        </div >
    );
}
